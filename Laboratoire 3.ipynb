{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappel Google Colab\n",
    "\n",
    "Tout d'abord, sélectionnez l'option GPU de Colab avec *Edit > Notebook settings* et sélectionner GPU comme Hardware accelerator. \n",
    "Installer ensuite deeplib avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ulaval-damas/glo4030-labs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 3: Optimisation\n",
    "\n",
    "## Partie 1: Fonctions d'optimisation\n",
    "\n",
    "Dans cette section, vous testerez différentes fonctions d'optimisation et observerez leurs effets sur l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import poutyne as pt\n",
    "\n",
    "from deeplib.history import History\n",
    "from deeplib.datasets import train_valid_loaders, load_cifar10\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from deeplib.net import CifarNet\n",
    "\n",
    "from deeplib.training import train, validate_ranking, test\n",
    "from deeplib.visualization import show_2d_function, show_optimization, show_worst, show_random, show_best\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Un exemple jouet\n",
    "\n",
    "On va commencer par explorer les effets des variantes de SGD avec un exemple jouet. L'exemple jouet va consister en une régression linéaire simple en 2 dimensions avec laquelle on sera en mesure de visualiser l'impact des différentes variantes de SGD. En effet, dans cette section, on va jouer avec trois paramètres de SGD: le taux d'apprentissage, le momentum et l'accélération de Nesterov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisations notre jeu de données jouet qui va contenir seulement 3 points en 2 dimensions ainsi que 3 valeurs à régresser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,1],[0,-1],[2,.5]], dtype=torch.float32)\n",
    "y = torch.tensor([[-1.], [3], [2]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors d'une régression linéaire, on souhaite trouver des poids $w^*$ qui minimise pour chaque exemple $(x_i, y_i)$ la perte quadratique entre $x_i \\cdot w$ et $y_i$. Mathématiquement, voici la fonction que l'on souhaite optimiser:\n",
    "$$F(w) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i \\cdot w - y_i)^2$$\n",
    "On souhaite donc trouver les poids optimaux $w^*$ qui minimise $F(w)$.\n",
    "$$w^* = \\text{argmin}_w F(w)$$\n",
    "La cellule ci-dessous est cette fonction objectif en fonction des paramètres $w$ que l'on souhaite trouver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(w):\n",
    "    return torch.mean((x @ w - y) ** 2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous vous en rappelez peut-être, la solution d'une régression linéaire a une forme analytique qui est la suivante.\n",
    "$$w^* = (X^TX)^{-1}X^TY$$\n",
    "La cellule ci-dessous trouve la solution pour notre problème jouet en utilisant cette formule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_opt = torch.inverse(x.T @ x) @ x.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser la fonction `show_2d_function` de la librairie `deeplib`. La librairie `deeplib` est une libraire écrite spécialement pour les notebook de ce cours. La fonction `show_2d_function` permet de visualiser notre fonction objectif avec des courbes de niveau. Les deux axes correspondent à différentes valeurs pour les 2 poids respectifs de $w$ pour notre régression linéaire en 2 dimensions. La couleur des courbes de niveau donne la valeur de la fonction objectif. L'étoile rouge correspond à $w^*$, notre valeur optimale des poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_2d_function(objective_function, optimal=w_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les prochaines cellules définissent deux fonctions. \n",
    "\n",
    "La première fonction se charge d'optimiser notre fonction objectif à la manière des réseaux de neurones en utilisant l'optimiseur SGD de PyTorch. La fonction retourne l'historique des poids $w$ de chaque itération ainsi que l'historique des valeurs de perte. Des commentaires dans cette fonction ont été laissés afin que vous puissiez comprendre le déroulement de l'optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(learning_rate, momentum, nesterov, nb_iter=20):\n",
    "    \"\"\"\n",
    "    Optimise la fonction objectif à la manière de PyTorch avec l'optimiseur SGD.\n",
    "    \n",
    "    Args:\n",
    "        learning_rate: Le taux d'apprentissage.\n",
    "        momentum: La valeur du momentum.\n",
    "        nesterov: Si l'accélération de Nesterov est désirée.\n",
    "        nb_iter: Le nombre d'itérations effectué.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple `(w_history, loss_history)` où `w_history` correspond à \n",
    "        l'historique des poids lors de l'optimisation et `loss_history`\n",
    "        correspond à l'historique de la valeur de la fonction objectif \n",
    "        ou fonction de perte dans le cadre des réseaux de neurones.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Notre réseau: une couche linéaire sans biais. Essentiellement, 2 poids.\n",
    "    neuron = nn.Linear(2, 1, bias=False)\n",
    "    \n",
    "    # La fonction de perte quadratique.\n",
    "    loss_function = nn.MSELoss()\n",
    "    \n",
    "    # Initialise l'optimiseur SGD\n",
    "    optimizer = optim.SGD(neuron.parameters(), lr=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "\n",
    "    # À la différence des réseaux de neurones, on ne divise pas en epochs\n",
    "    # et en batchs étant donné que notre jeu de données contient seulement\n",
    "    # 3 points et que notre problème est convexe et donc résoluble avec une\n",
    "    # simple descente de gradient. On fera donc un certain nombre d'itérations\n",
    "    # pour trouver la solution du problème. On pourrait voir une itération comme \n",
    "    # un epoch avec une seule batch contenant le jeu de données entier.\n",
    "    # Pour chaque itération, on y va à \n",
    "    # la manière des réseaux de neurones:\n",
    "    # - On effectue une prédiction;\n",
    "    # - On calcule notre perte;\n",
    "    # - On fait la rétropropagation (backpropagation) via la méthode backward();\n",
    "    # - On met à jour les poids avec l'optimiseur.\n",
    "    w_history = []\n",
    "    loss_history = []\n",
    "    for t in range(nb_iter):\n",
    "        y_pred = neuron(x)\n",
    "        loss = loss_function(y_pred, y)         \n",
    "        w_history.append(neuron.weight.squeeze(0).detach().clone().numpy())\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return w_history, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième fonction trace des graphiques permettant de visualiser l'optimisation effectuée par la première fonction. La fonction ne fait qu'appeler la fonction `show_optimization` définie dans `deeplib` en lui passant en paramètre les historiques retournées par la fonction d'optimisation, la fonction objectif ainsi que les paramètres optimaux que nous avons calculés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_objective_optimization(w_history, loss_history, **kwargs):\n",
    "    return show_optimization(w_history, loss_history, objective_function, optimal=w_opt, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser ces deux fonctions pour pouvoir visualiser l'impact de trois paramètres de SGD: le taux d'apprentissage, le momentum et l'accélération de Nesterov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "momentum = 0\n",
    "nesterov = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisons maintenant notre fonction avec les valeurs ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "show_objective_optimization(w_history, loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'après 10 itérations, l'optimisation a relativement convergé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices\n",
    "\n",
    "Pour les exercices ci-dessous, vous pouvez utiliser des fonctions comme [`numpy.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html), [`numpy.logspace`](https://numpy.org/doc/stable/reference/generated/numpy.logspace.html) ou [`numpy.geomspace`](https://numpy.org/doc/stable/reference/generated/numpy.geomspace.html) permettant d'obtenir une liste de valeurs à tester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testez différentes valeurs entre 0 et 1 du taux d'apprentissage en complétant la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "momentum = 0.\n",
    "nesterov = False\n",
    "for learning_rate in [...]: # TODO à compléter avec différentes valeurs\n",
    "    w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "    show_objective_optimization(w_history, loss_history, title=f\"Learning rate: {learning_rate:.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testez différentes valeurs entre 0 et 1 pour le momentum en complétant la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "nesterov = False\n",
    "for momentum in [...]: # TODO à compléter avec différentes valeurs\n",
    "    w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "    show_objective_optimization(w_history, loss_history, title=f\"Momentum: {momentum:.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testez différentes valeurs entre 0 et 1 pour le momentum avec l'accélération de Nesterov en complétant la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "nesterov = True\n",
    "for momentum in [...]: # TODO à compléter avec différentes valeurs\n",
    "    w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "    show_objective_optimization(w_history, loss_history, title=f\"Momentum: {momentum:.2g} avec Nesterov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Que pouvons-nous remarquer sur l'impact du taux d'apprentissage sur l'optimisation?\n",
    "- Que pouvons-nous remarquer sur l'impact du momentum sur l'optimisation?\n",
    "- Que pouvons-nous remarquer sur l'impact de l'accélération de Nesterov sur l'optimisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Un exemple plus près de la réalité\n",
    "\n",
    "Testons maintenant différents optimiseurs sur un vrai réseau de neurones avec un vrai jeu de données. Comme dans les labos précédents, on utilise le jeu de données CIFAR10 avec un simple réseau à convolution.\n",
    "\n",
    "Initialisons le jeu de données et quelques hyperparamètres qui vont rester constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.01\n",
    "n_epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le reste de ce notebook et dans les prochains laboratoires, nous allons utiliser la fonction `train` qui est définie dans la librairie `deeplib`. La fonction utilise la librairie [Poutyne](https://poutyne.org). Comme vu dans le laboratoire 1, Poutyne nous donne un meilleur affichage de l'évolution de l'entraînement comparativement à notre boucle d'entraînement personnalisée que nous avions fait à la main. Comme on va le voir plus loin, l'utilisation de Poutyne implique nous allons devoir utiliser des callbacks de Poutyne pour les horaires d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    " - Comparez trois différentes stratégies d'optimisation:\n",
    "1. [SGD](http://pytorch.org/docs/master/optim.html#torch.optim.SGD)\n",
    "2. SGD + Momentum accéléré de Nesterov\n",
    "3. [Adam](http://pytorch.org/docs/master/optim.html#torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par l'entraîner avec SGD (sans momentum ni accélération de Nesterov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "history_sgd = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_sgd.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Complétez cette cellule pour entraîner avec SGD + Momentum accéléré de Nesterov. Utilisez un momentum de 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "#optimizer =\n",
    "history_SGDMN = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_SGDMN.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Complétez cette cellule pour entraîner avec Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "#optimizer =\n",
    "history_adam = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_adam.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Quelle méthode semble être la meilleure dans ce cas-ci?\n",
    "- Remarquez-vous une différence d'overfitting?\n",
    "- Dans une nouvelle cellule, changez le taux d'apprentissage de Adam pour 0.001. Que remarquez-vous maintenant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la réponse à la question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "#optimizer =\n",
    "history_adam = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_adam.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2: Horaire d'entraînement\n",
    "\n",
    "Une pratique courante utilisée en apprentissage profond est de faire diminuer le taux d'apprentissage pendant l'entraînement.\n",
    "\n",
    "Pour ce faire, PyTorch fournit plusieurs fonctions (ExponentialLR, LambdaLR, MultiStepLR, etc.).  Dans ce notebook, on utilisera les [callbacks correspondant de Poutyne](https://poutyne.org/callbacks.html#lr-schedulers) qui cachent sous le capot les fonctions de PyTorch.\n",
    "\n",
    "Voici un exemple avec ExponentialLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "n_epoch = 10\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "gamma = 0.8\n",
    "scheduler = pt.ExponentialLR(gamma)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons la valeur du taux d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.display(display_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    "- Utilisez [MultiStepLR](http://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.MultiStepLR) pour modifier le taux d'apprentissage pour un epoch précis.\n",
    "\n",
    "1. Commencez avec un taux d'apprentissage trop élevé pour que le réseau puisse apprendre quelque chose.\n",
    "2. Diminuez-le progressivement jusqu'à ce que le réseau apprenne.\n",
    "3. Trouvez le moment où la validation semble avoir atteint un plateau.\n",
    "4. Diminuez le taux par 2 à ce moment et réentraîner le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "epoch_list = [] # TODO liste à remplir au fur et à mesure que les points 3 et 4 sont itérés.\n",
    "\n",
    "batch_size = 128\n",
    "lr = 10\n",
    "n_epoch = 20\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = pt.MultiStepLR(milestones=epoch_list, gamma=0.5, verbose=True)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history.display(display_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Voyez-vous une différence en diminuant le taux d'apprentissage par 2 après x epochs?\n",
    "- Pourquoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin sur les horaires d'entraînement\n",
    "\n",
    "On vient de faire \"à la main\" ce que la classe [ReduceLROnPlateau](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau) de PyTorch nous permet de faire automatiquement. Essentiellement, cette classe nous permet de monitorer une métrique et de réduire le taux d'apprentissage lorsque cette métrique stagne pour un certain nombre d'epochs. Ce nombre d'epoch est appelé la \"patience\". Nous allons utiliser le callback [poutyne.ReduceLROnPlateau](https://poutyne.org/callbacks.html#poutyne.ReduceLROnPlateau) de Poutyne qui prend en paramètre le nom de la métrique à monitorer en plus des autres arguments de la classe de PyTorch.\n",
    "\n",
    "Notez bien la description du paramètre `patience` dans la documentation de PyTorch:\n",
    "> **patience** - Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then.\n",
    "\n",
    "Dans la cellule ci-dessous, on monitore l'exactitude en validation avec une patience de 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.5\n",
    "n_epoch = 20\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = pt.ReduceLROnPlateau(monitor='val_acc', mode='max', patience=1, factor=0.5, verbose=True)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.display(display_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3: Batch Normalization\n",
    "\n",
    "Voici l'architecture du réseau de neurones convolutionnels que vous avez utilisé jusqu'à présent pour faire de la classification sur Cifar10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CifarNetBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 50, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(50, 150, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(150 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    "- Modifier l'architecture du réseau en ajoutant de la batch normalization entre les couches de convolutions et les ReLUs (essentiellement, on devait avoir `Conv2d -> BatchNorm2d -> ReLU`) et entraîner le nouveau réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNetBatchNorm()\n",
    "model.cuda()\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "n_epoch = 5\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- Comparer l'entraînement du réseau avec et sans la batch normalization (Section 1.2 avec SGD, où on a entraîné le réseau sans batch normalization avec le même taux d'apprentissage). Que remarquez-vous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet de la batch normalization sur le taux d'apprentissage\n",
    "\n",
    "Commençons par entraîner un réseau avec un taux d'apprentissage élevé. Vous pouvez augmenter le nombre d'epochs si vous voulez voir une plus grande différence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "batch_size = 1024\n",
    "n_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons maintenant d'entraîner le réseau utilisant la batch normalization avec les mêmes hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNetBatchNorm()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Que pouvez-vous conclure sur l'effet de la batch normalization sur le taux d'apprentissage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse\n",
    "\n",
    "Après l'entraînement, il est important d'analyser les résultats obtenus.\n",
    "Commençons par tester le réseau en utilisant la fonction `validate_ranking`.\n",
    "Cette fonction sépare les résultats bien classés des erreurs et retourne pour chaque image, un score (qu'on peut voir comme une probabilité), la vraie classe et la classe prédite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good, errors = validate_ranking(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, regardons quelques exemples d'images bien classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et quelques exemples mal classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi possible de regarder les exemples où le réseau est le plus confiant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou l'inverse, ceux qui ont obtenus les moins bons scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_worst(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, il peut être intéressant de regarder les exemples les plus difficiles.\n",
    "Soit ceux qui ont été bien classés, mais qui ont eu un mauvais score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_worst(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou ceux qui ont été mal classés, mais qui ont quand même réussi à obtenir un bon score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions \n",
    "- En observant les résultats obtenus, que pouvez-vous dire sur les performances du réseau?\n",
    "- Quelle classe semble être facile? Pourquoi?\n",
    "- Quelle classe semble être difficile? Pourquoi?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
