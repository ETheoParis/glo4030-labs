{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel Google Colab\n",
    "\n",
    "Tout d'abord, sélectionnez l'option GPU de Colab avec *Edit > Notebook settings* et sélectionner GPU comme Hardware accelerator. \n",
    "Installer ensuite deeplib avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ulaval-damas/glo4030-labs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 4: Régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import poutyne as pt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from deeplib.datasets import load_cifar10, load_mnist, train_valid_loaders\n",
    "from deeplib.net import CifarNet, CifarNetBatchNorm\n",
    "from deeplib.training import train, test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "cifar_train, cifar_test = load_cifar10()\n",
    "mnist_train, mnist_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1: Régularisation L1 et L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation manuelle\n",
    "Dans la communauté de l'apprentissage profond, la régularisation L2 est communément appelée **weight decay**. \n",
    "\n",
    "Il est toutefois à noter que le **weight decay** et la régularisation L2 ne sont pas équivalents dans tous les cas. Ces deux méthodes sont équivalentes lorsque l'on utilise un optimiseur de type SGD, mais elles ne le sont pas pour des optimiseurs à gradients adaptatifs comme Adam. Voir l'article [Decoupled Weight Decay Regularization](https://arxiv.org/pdf/1711.05101.pdf) pour plus de détails sur la distinction entre ces deux méthodes.\n",
    "\n",
    "Dans le cadre de ce laboratoire, on utilise exclusivement l'optimiseur SGD, on peut donc considérer les termes **weight decay** et la régularisation L2 comme équivalents.\n",
    "\n",
    "Dans PyTorch, les optimiseurs de `torch.optim` ont un paramètre `weight_decay` pour utiliser cette régularisation. Par contre, on peut facilement implémenter manuellement la régularisation L2 comme une pénalité sur la norme des poids (voir le [chapitre 7.1](http://www.deeplearningbook.org/contents/regularization.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    " - Complétez la fonction *loss_init* en ajoutant manuellement la pénalité sur les paramètres du réseau selon une régularisation L1 ou L2. Le paramètre *reg_alpha* correspond à l'hyperparamètre de régularisation $\\alpha$ du livre ($\\lambda$ dans les acétates du cours). Le paramètre *p* correspond à l'ordre de la norme: $p=1$ pour la norme L1 et $p=2$ pour la norme L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_init(parameters=[], reg_alpha=0, p=2):\n",
    "    cross_entropy = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def loss_function(output, targets):\n",
    "        loss = cross_entropy(output,targets)\n",
    "\n",
    "        for param in parameters:\n",
    "            # TODO Ajoutez la pénalité sur les paramètres\n",
    "        \n",
    "        return loss\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez votre implémentation de la régularisation par la norme L2 ($p=2$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "net = CifarNet()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "loss = loss_init(list(net.parameters()), reg_alpha=1e-3, p=2)\n",
    "\n",
    "history = train(net, optimizer, cifar_train, n_epoch=5, batch_size=64, use_gpu=True, criterion=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez votre implémentation de la régularisation par la norme L1 ($p=1$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "net = CifarNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "loss = loss_init(list(net.parameters()), reg_alpha=1e-3, p=1)\n",
    "\n",
    "history = train(net, optimizer, cifar_train, n_epoch=5, batch_size=64, use_gpu=True, criterion=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation du *weight decay*\n",
    "\n",
    "Explorons maintenant l'utilisation du paramètre `weight_decay` disponible dans les optimiseurs de `PyTorch` pour effectuer de la régularisation L2. Nous allons entrainer un réseau de neurones avec régularisation L2 et un autre sans pour pouvoir observer l'impact de la régularisation sur l'apprentissage et le réseau appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "batch_size = 64\n",
    "lr = 0.1\n",
    "n_epoch = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseau sans régularisation L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "net_without_l2 = CifarNet()\n",
    "optimizer_without_l2 = optim.SGD(net_without_l2.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "history_without_l2 = train(net_without_l2, optimizer_without_l2, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_without_l2.display()\n",
    "print('Précision en test: {:.2f}'.format(test(net_without_l2, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseau avec régularisation L2 (*weight decay*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "net_l2 = CifarNet()\n",
    "optimizer_l2 = optim.SGD(net_l2.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "history_l2 = train(net_l2, optimizer_l2, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_l2.display()\n",
    "print('Précision en test: {:.2f}'.format(test(net_l2, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Quel est l'effet de la régularisation L2 sur l'entraînement du réseau? \n",
    "    \n",
    "- Si vous utilisez un `weight_decay` trop grand (exemple 0.1) qu'arrive-t-il? Pourquoi? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, analysez avec un histogramme la distribution des poids appris par les réseaux avec ou sans régularisation. \n",
    "\n",
    "- Que remarquez-vous? \n",
    "    \n",
    "- Essayez d'autres valeurs de weight decay (1e-2, 1e-4) et observez l'impact sur la distribution des poids appris. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_to_weight_array(net):\n",
    "    weights = []\n",
    "    for p in net.parameters():\n",
    "        p_numpy = p.data.cpu().numpy()\n",
    "        weights.append(p_numpy.reshape((-1))) # Reshape to 1D array\n",
    "    return np.concatenate(weights)\n",
    "\n",
    "weights_without_l2 = net_to_weight_array(net_without_l2)\n",
    "weights_l2 = net_to_weight_array(net_l2)\n",
    "\n",
    "print(\"Poids sans régularisation L2: variance {:.4f}, maximum {:.4f}.\".format(np.var(weights_without_l2), \n",
    "                                                                              np.max(np.abs(weights_without_l2))))\n",
    "print(\"Poids avec régularisation L2: variance {:.4f}, maximum {:.4f}.\".format(np.var(weights_l2), \n",
    "                                                                              np.max(np.abs(weights_l2))))\n",
    "\n",
    "# Visualisation\n",
    "plt.hist(weights_without_l2, bins=250, range=(-0.3, 0.3), alpha =0.5, label=\"Sans régularisation L2\")\n",
    "plt.hist(weights_l2, bins=250, range=(-0.3, 0.3), alpha=0.5, label=\"Avec régularisation L2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2: Early stopping\n",
    "\n",
    "Commencez par entraîner un réseau pour un grand nombre d'époques. L'historique d'entraînement nous servira de base pour les questions qui suivent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "net = CifarNetBatchNorm()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-3, nesterov=True, momentum=0.9)\n",
    "scheduler = pt.ReduceLROnPlateau(monitor='val_acc', mode='max', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "history = train(net, optimizer, cifar_train, n_epoch=40, batch_size=64, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "- En regardant les graphiques ci-dessus, quel est le meilleur moment pour arrêter l'entraînement? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme 7.1 du livre (voir http://www.deeplearningbook.org/contents/regularization.html page 244) décrit le paramètre de patience `p` dans le contexte d'un algorithme de *early stopping* (**Attention**: le paramètre de patience `p` du *early stopping* n'a pas de lien avec le paramètre `p` correspondant à l'ordre d'une norme de la section précédente).\n",
    "\n",
    "#### Exercice\n",
    "- Analysez l'effet du choix de `p` sur les données de l'entraînement précédent. Regardez pour `p = 1,2,5,10,15`, quelle époque avec quelle précision en validation est choisie. Implémentez un algorithme effectuant du *early stopping* en utilisant l'historique `val_accuracy` de l'entraînement que vous venez d'exécuter pour vos tests (à la place d'entraîner le réseau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historique\n",
    "val_accuracy_history = history.history['val_acc']\n",
    "\n",
    "# Patience\n",
    "p = 5\n",
    "\n",
    "best_val_accuracy = -np.inf\n",
    "best_epoch = -1\n",
    "\n",
    "# TODO Implémentez un algorithme de early stopping sur l'historique\n",
    "            \n",
    "print(\"Pour patience p={}, la meilleure époque est {}, avec précision en validation de {:.2f}.\".format(p, best_epoch, best_val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "- Identifiez des problèmes pratiques potentiels lors de l'utilisation du *early stopping*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin sur le early stopping\n",
    "Avec Poutyne, on peut effectuer le *early stopping* automatiquement grâce au callback [EarlyStopping](https://poutyne.org/callbacks.html#poutyne.EarlyStopping). Il faut spécifier la métrique à monitorer ainsi que la patience, et on peut également contrôler l'amplitude minimum d'un changement pour que celui-ci soit qualifié comme une amélioration avec le paramètre `min_delta`. L'entraînement va donc s'arrêter automatiquement lorsqu'il n'y a plus d'amélioration pour un nombre consécutif d'époques correspondant à la patience, prévenant possiblement le calcul inutile de plusieurs époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patience\n",
    "p = 3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "net = CifarNetBatchNorm()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-3, nesterov=True, momentum=0.9)\n",
    "scheduler = pt.ReduceLROnPlateau(monitor='val_acc', mode='max', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# Early stopping sous la forme d'un Callback\n",
    "early_stopping = pt.EarlyStopping(monitor='val_acc', mode='max', min_delta=1e-5, patience=p, verbose=True)\n",
    "\n",
    "history = train(net, optimizer, cifar_train, n_epoch=40, batch_size=64, callbacks=[scheduler, early_stopping], use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3: Dropout\n",
    "Cette section a pour but d'analyser l'effet du dropout dans un réseau fully connected. Nous ferons cette analyse en reprenant l'exercice du laboratoire 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "- Dans le réseau suivant, implémentez la fonction `forward()` formée de couches linéaires suivies d'activation   `Relu` en ajoutant du dropout ([Indice](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.dropout)) après l'activation si `self.use_dropout == True` . Utilisez une probabilité de dropout de `0.3` indiqué par `self.dropout_p` et ne faites pas de dropout sur la couche de sortie. N'ajoutez **pas de softmax** car la fonction `deeplib.training.train()` utilise par défaut `CrossEntropyLoss`, ce qui le fait pour vous. \n",
    "\n",
    "> **ATTENTION!** Vous devez bien fixer l'argument `training` de dropout. Vous pouvez savoir si modèle est en entraînement ou en évaluation avec `self.training`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_layers, hidden_size=100, use_dropout=True, dropout_p=0.3):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.use_dropout = use_dropout\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Initialisation des couches\n",
    "        layer_sizes = [28*28] + [self.hidden_size]*n_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for input_size, output_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layer = nn.Linear(input_size, output_size)\n",
    "            layer.weight.data.normal_(0.0, math.sqrt(2 / input_size))\n",
    "            layer.bias.data.fill_(0)\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        \n",
    "        # Couche de sortie avec une neurone par classe\n",
    "        self.output_layer = nn.Linear(hidden_size,10)\n",
    "        self.output_layer.weight.data.normal_(0.0, math.sqrt(2 / hidden_size))\n",
    "        self.output_layer.bias.data.fill_(0)              \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 28*28)\n",
    "        for layer in self.layers:\n",
    "            # TODO\n",
    "            \n",
    "        return self.output_layer(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "- Quelle est l'importance de l'argument `training` de la fonction de dropout? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez un réseau avec dropout et un réseau sans dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "lr = 0.01\n",
    "batch_size = 64\n",
    "n_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseau sans dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_without_dropout = MnistModel(2, use_dropout=False)\n",
    "optimizer_without_dropout = optim.SGD(net_without_dropout.parameters(), lr, nesterov=True, momentum=0.9)\n",
    "\n",
    "history_without_dropout = train(net_without_dropout, optimizer_without_dropout, mnist_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_without_dropout.display()\n",
    "print('Précision en test: {:.2f}'.format(test(net_without_dropout, mnist_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseau avec dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_with_dropout = MnistModel(2, use_dropout=True, dropout_p=0.3)\n",
    "optimizer_with_dropout = optim.SGD(net_with_dropout.parameters(), lr, nesterov=True, momentum=0.9)\n",
    "\n",
    "history_with_dropout = train(net_with_dropout, optimizer_with_dropout, mnist_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_with_dropout.display()\n",
    "print('Précision en test: {:.2f}'.format(test(net_with_dropout, mnist_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Quel est l'effet du dropout sur l'entraînement du réseau? \n",
    "    \n",
    "- Essayez plusieurs valeurs de dropout et observez les effets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
